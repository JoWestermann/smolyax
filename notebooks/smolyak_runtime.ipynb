{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e318857-3396-46af-9dfd-8160a5c7193f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, itertools, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 16, 'figure.figsize': (40, 8), 'font.family': 'serif', 'text.usetex': False, 'pgf.rcfonts': False})\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import jax\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "from smolyax import indices, nodes\n",
    "from smolyax.interpolation import SmolyakBarycentricInterpolator\n",
    "\n",
    "def target_f(x, theta, r) :\n",
    "    return 1/(1+ theta * np.sum(x * (np.arange(x.shape[-1]) + 2)**(-r), axis=-1))\n",
    "\n",
    "r, theta = 2., .1\n",
    "f = lambda x : target_f(x, theta, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7259ab-f965-4924-bb6f-18f44ad0214f",
   "metadata": {},
   "source": [
    "# `SmolyakBarycentricInterpolator` runtime\n",
    "\n",
    "Runtime is a key performance metric for interpolation methods. This notebook empirically sketches how runtime of key algorithm components (mainly setup time and evalutation time) develops in dependence of the dimensionality of the input domain and the number of interpolation points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62980a16-47a9-4ac8-905d-7be00a9808f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [10,1000]\n",
    "n_inputs = 250\n",
    "m_max = 10_000\n",
    "n_tests = 10\n",
    "\n",
    "cost_setup = np.zeros((len(dimensions), n_tests))\n",
    "cost_eval = np.zeros((len(dimensions), n_tests))\n",
    "ns = np.zeros((len(dimensions), n_tests))\n",
    "\n",
    "for i, d in enumerate(dimensions) :\n",
    "    node_gen = nodes.Leja(dim=d)\n",
    "    k  = [np.log((ki+2)**(r)/theta) for ki in range(d)]\n",
    "    max_t = indices.find_approximate_threshold(k, m_max, node_gen.is_nested)\n",
    "\n",
    "    for j, t in enumerate(np.linspace(2, max_t, n_tests)) : \n",
    "        \n",
    "        # measure setup time\n",
    "        t_start = time.time()\n",
    "        ip = SmolyakBarycentricInterpolator(node_gen=node_gen, k=k, t=t, d_out=1, f=f, n_inputs=n_inputs)\n",
    "        cost_setup[i,j] = time.time() - t_start\n",
    "        ns[i,j] = ip.n_f_evals\n",
    "\n",
    "        # measure eval time\n",
    "        x = node_gen.get_random(n_inputs)\n",
    "        t_start = time.time()\n",
    "        y = ip(x)\n",
    "        cost_eval[i,j] = time.time() - t_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2880d7be-b967-453e-9cb9-f7c01aeefe6c",
   "metadata": {},
   "source": [
    "## 1. Setup time\n",
    "\n",
    "The plot below shows the dependence of setup time on the number of interpolation nodes $m$, for varying dimension $d$ of the input domain on which to interpolate.\n",
    "\n",
    "The setup time includes generating the multi-index set and the interpolation nodes and weights, allocating the necessary data structures, calling the (in this case, simplistic) target function at the interpolation nodes, as well as a sample evaluation to trigger jit-compilation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2d4805-110a-4a19-b9e3-b93c83eae4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15,6))\n",
    "for i, d in enumerate(dimensions) :\n",
    "    ax.loglog(ns[i], cost_setup[i], marker='o', label=rf'd={d}')\n",
    "ax.set_xlabel(r'$n$'); ax.set_ylabel(r'$t [s]$'); ax.grid(); ax.legend(); ax.set_title(rf'setup time'); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cae1ec-644f-4d82-b8f8-e67161bbccdf",
   "metadata": {},
   "source": [
    "## 2. Evaluation time \n",
    "\n",
    "Following the same setup as in 1., we here show the runtime of evaluating the interpolant on a batch of size $n_{\\rm inputs} = 250$.\n",
    "\n",
    "**Note:** Maybe counterintuitively at first sight, the curve for $d=1000$ runs mostly below the curve for $d=10$. This could be caused by the fact that for a fixed number of interpolation nodes $m$, in higher dimensions the nodes are more distributed and the maximal number of nodes in each dimension is lower. This leads to potentially more but smaller tensors than in lower dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9244f8c-a577-4f5f-899b-4daf7e170ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15,6))\n",
    "for i, d in enumerate(dimensions) :\n",
    "    ax.loglog(ns[i], cost_eval[i], marker='o', label=rf'd={d}')\n",
    "ax.set_xlabel(r'$n = |\\Lambda|$'); ax.set_ylabel(r'$t [s]$'); ax.grid(); ax.legend(); ax.set_title(rf'evaluation time per input batch'); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05536cca-cd0b-41ca-8e29-26ad3146feff",
   "metadata": {},
   "source": [
    "## 3. Dependence of evaluation time per sample on the size of the input batch\n",
    "\n",
    "Here, we keep the number of interpolation nodes fixed at $m = 1000$ and study how the time for evaluating the interpolant at a single input sample depends on the size of the input batch $n_{\\rm inputs}$.\n",
    "\n",
    "We observe that computational overhead affects small input batches, with the time-per-sample then stabilizing for higher dimensions for batch sizes in the order of $10^2$ to $10^3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b617e179-bded-4c83-b532-133ba6a55a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [10,1000]\n",
    "n_inputs_list = [1,10,100,1000]\n",
    "n_max = 1000\n",
    "\n",
    "cost_eval = np.zeros((len(dimensions), len(n_inputs_list)))\n",
    "ns = np.zeros((len(dimensions), len(n_inputs_list)))\n",
    "\n",
    "for i, d in enumerate(dimensions) :\n",
    "    node_gen = nodes.Leja(dim=d)\n",
    "    k = [np.log((ki+2)**(r)/theta) for ki in range(d)]\n",
    "    t = indices.find_approximate_threshold(k, n_max, node_gen.is_nested)\n",
    "    \n",
    "    for j, n_j in enumerate(n_inputs_list) :\n",
    "        ip = SmolyakBarycentricInterpolator(node_gen=node_gen, k=k, t=t, d_out=1, f=f, n_inputs=n_j)\n",
    "        x = node_gen.get_random(n_j)\n",
    "        t_start = time.time()\n",
    "        y = ip(x)\n",
    "        cost_eval[i,j] = (time.time() - t_start) / n_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cd666e-a8b6-4e69-8480-e9b34a44dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15,6))\n",
    "for i, d in enumerate(dimensions) :\n",
    "    ax.loglog(n_inputs_list, cost_eval[i], marker='o', label=rf'd={d}')\n",
    "ax.set_xlabel(r'n_inputs'); ax.set_ylabel(r'$t [s]$'); ax.grid(); ax.legend(); ax.set_title(rf'evaluation time per sample');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smolyax",
   "language": "python",
   "name": "smolyax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
